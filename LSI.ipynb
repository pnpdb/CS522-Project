{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c02d7dc3-5acf-46ff-8e37-170327cbe2f5",
   "metadata": {},
   "source": [
    "# LSI text preprocessing example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a232b3b-0e37-4d15-9b5a-6e8f33a28b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_dictionary, common_corpus\n",
    "from gensim.models import LsiModel\n",
    "from Common.DataCenter import data_center\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8d9927-d9c5-4a42-9b8d-e6c9b0c8859b",
   "metadata": {},
   "source": [
    "首先给出官方文档中的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13a30a25-a928-497e-b63b-eaf2f5c152bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LsiModel(common_corpus, id2word=common_dictionary)\n",
    "vectorized_corpus = model[common_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837a04be-64be-4f79-aaaf-31631afd8396",
   "metadata": {},
   "source": [
    "非常简单粗暴，传入corpus，以及传入字典，就能构造出LSA模型。得到模型以后，传入了corpus，就能得到向量。下面我们从头构造，来了解一下它是怎么运作的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c4b8a1-5204-46d4-897d-ddc4015b12d8",
   "metadata": {},
   "source": [
    "举例： 如何构造corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a801099-b34c-451e-ab46-ce0297fa9b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from gensim import corpora\n",
    "# 这个就是文档库，是个字符串数组，列表中的每个元素是个字符串\n",
    "documents = [\n",
    "    \"Human machine interface for lab abc computer applications\",\n",
    "    \"A survey of user opinion of computer system response time\",\n",
    "    \"The EPS user interface management system\",\n",
    "    \"System and human system engineering testing of EPS\",\n",
    "    \"Relation of user perceived response time to error measurement\",\n",
    "    \"The generation of random binary unordered trees\",\n",
    "    \"The intersection graph of paths in trees\",\n",
    "    \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "    \"Graph minors A survey\",\n",
    "]\n",
    "# 将文档中的所有单词转换为小写，移除刁stop words，并按空格分割\n",
    "# remove common words and tokenize\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [\n",
    "    [word for word in document.lower().split() if word not in stoplist]\n",
    "    for document in documents\n",
    "]\n",
    "# 这里删除罕见词，将只出现过1次的词删掉\n",
    "# remove words that appear only once\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [\n",
    "    [token for token in text if frequency[token] > 1]\n",
    "    for text in texts\n",
    "]\n",
    "# 将文档库的所有单词存入字典，内部自动赋予ID\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "# 重新将文档库进行doc2bow，每篇文章由单词数组，转换为了[(id1, number),(id2, number), ... ]的形式，每个独一无二的单词对应一个id\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c2d419-d781-48ec-b8e6-763b1e9795a6",
   "metadata": {},
   "source": [
    "doc2bow可以将文档转换为内部定义的数字token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bcf383a-f321-4fd6-8b77-705dc111f9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 1), (10, 2)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.doc2bow(['survey', 'graph', 'graph'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbcebe2-5be9-4339-a155-01d35f774669",
   "metadata": {},
   "source": [
    "这里的4代表survey，后面的数字1代表survey出现了一次；10代表graph，后面的2代表出现了2次。  \n",
    "总结一下，我们的文档库是用列表的形式表示，列表的一个元素是一个字符串。我们手工将字符串转换成小写以后，通过空格进行分割，这样每个文档就对应了个字符串的数组，每个数组元素就是一个单词。然后通过Dictionary，将这个二级数组转换为dictionary，这里的dictionary将所有单词存起来，每个单词指定了一个索引。  \n",
    "接下来对于文档库的每一个文档，用doc2bow函数，转换为[(id1, number), (id2, number), ...]的形式。  \n",
    "现在使用LsiModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "016ccf60-5f33-4bda-a7b8-8eeeff71e501",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "testModel = LsiModel(corpus=corpus, id2word=dictionary)\n",
    "vec_corpus = model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18ccc0e-7f13-4117-99e2-71dcf36b69b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "把topic按照重要程度列出来，每个默认列前10个单词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f84ebf1-657d-4c3d-a2ae-d63b09e61b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.644*\"system\" + 0.404*\"user\" + 0.301*\"eps\" + 0.265*\"time\" + 0.265*\"response\" + 0.240*\"computer\" + 0.221*\"human\" + 0.206*\"survey\" + 0.198*\"interface\" + 0.036*\"graph\"'),\n",
       " (1,\n",
       "  '-0.623*\"graph\" + -0.490*\"trees\" + -0.451*\"minors\" + -0.274*\"survey\" + 0.167*\"system\" + 0.141*\"eps\" + 0.113*\"human\" + -0.107*\"response\" + -0.107*\"time\" + 0.072*\"interface\"'),\n",
       " (2,\n",
       "  '-0.426*\"response\" + -0.426*\"time\" + 0.361*\"system\" + -0.338*\"user\" + 0.330*\"eps\" + 0.289*\"human\" + 0.231*\"trees\" + 0.223*\"graph\" + -0.178*\"survey\" + -0.164*\"computer\"'),\n",
       " (3,\n",
       "  '-0.595*\"computer\" + -0.552*\"interface\" + -0.415*\"human\" + 0.333*\"system\" + 0.188*\"eps\" + 0.099*\"user\" + 0.074*\"time\" + 0.074*\"response\" + -0.032*\"survey\" + 0.025*\"trees\"'),\n",
       " (4,\n",
       "  '0.594*\"trees\" + -0.537*\"survey\" + 0.332*\"user\" + -0.300*\"minors\" + 0.282*\"interface\" + -0.159*\"system\" + 0.115*\"eps\" + -0.107*\"computer\" + -0.106*\"human\" + 0.080*\"time\"'),\n",
       " (5,\n",
       "  '0.496*\"interface\" + -0.392*\"trees\" + 0.385*\"user\" + -0.341*\"human\" + 0.277*\"minors\" + 0.272*\"eps\" + -0.255*\"computer\" + -0.207*\"system\" + -0.170*\"response\" + -0.170*\"time\"'),\n",
       " (6,\n",
       "  '0.523*\"human\" + -0.467*\"survey\" + 0.339*\"minors\" + -0.302*\"computer\" + -0.288*\"trees\" + 0.283*\"response\" + 0.283*\"time\" + -0.166*\"system\" + 0.160*\"graph\" + -0.070*\"interface\"'),\n",
       " (7,\n",
       "  '-0.681*\"graph\" + 0.678*\"minors\" + 0.255*\"trees\" + 0.062*\"computer\" + -0.060*\"human\" + -0.036*\"survey\" + 0.034*\"system\" + -0.019*\"eps\" + -0.016*\"time\" + -0.016*\"response\"'),\n",
       " (8,\n",
       "  '0.579*\"survey\" + -0.492*\"computer\" + 0.407*\"human\" + -0.271*\"system\" + -0.232*\"graph\" + 0.225*\"trees\" + -0.183*\"minors\" + 0.165*\"eps\" + 0.109*\"interface\" + 0.054*\"response\"')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testModel.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5308b6d4-ccda-49b0-9db5-bb20d9ade401",
   "metadata": {},
   "source": [
    "下面给定一句话(query)，将其转换到latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a30fd1ef-a8c8-49f6-a291-d7c4a773b772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.4618210045327161), (1, 0.07002766527900023), (2, 0.12452907551899081), (3, -1.0097125584438564), (4, -0.21303040605626267), (5, -0.5959384533820675), (6, 0.2204175354609439), (7, 0.0018778773554747955), (8, -0.08576685494995556)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 0.6594664059797395),\n",
       " (1, 0.1421154440372992),\n",
       " (2, 0.2595687142084211),\n",
       " (3, -1.561952142099366),\n",
       " (4, 0.06873853289228493),\n",
       " (5, -0.1000604422714601),\n",
       " (6, 0.1499940942871652),\n",
       " (7, -0.008062159852297827),\n",
       " (8, 0.023163410616346095)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = \"Human computer interaction\"\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = testModel[vec_bow]  # convert the query to LSI space\n",
    "print(vec_lsi)\n",
    "testModel[corpus[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c777847-af26-4c51-a2de-9091de8435f2",
   "metadata": {},
   "source": [
    "我们能看出，它给出的格式是一个tuple列表，tuple的第一个元素代表topic id，第二个元素就代表在该topic下的取值。从而得到latent space下的向量。  \n",
    "下面使用data center中的数据，训练LSA，然后算出latent space下的vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdd7fcda-573f-492a-abc8-6572646271a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dc_format(D):\n",
    "    data = {'message':D[0] , 'sentiment':D[1]}\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dba11459-a374-4468-a436-1173a7b494f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 8000\n",
      "Validation size: 5000\n"
     ]
    }
   ],
   "source": [
    "dc = data_center('./twitter_sentiment_data.csv', test_size=8000, noisy_size=8000, validation_size=5000)\n",
    "test_df = dc_format(dc.get_test())\n",
    "val_df = dc_format(dc.get_validation())\n",
    "\n",
    "print(f\"Test size: {test_df.shape[0]}\")\n",
    "print(f\"Validation size: {val_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a01f467-ee43-41b7-813c-251400272599",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_gpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
