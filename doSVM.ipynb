{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# SVM - Climate Sentiment Multiclass Classification\n",
    "## CS522 Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "**Dataset:**  \n",
    "https://www.kaggle.com/code/luiskalckstein/climate-sentiment-multiclass-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "from Common.DataCenter import data_center\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def text_preprocessing(X_train, X_test):\n",
    "    # Convert texts to vectors\n",
    "    vectorizer  = TfidfVectorizer()\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec  = vectorizer.transform(X_test)\n",
    "    return X_train_vec, X_test_vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## One-hot encoding, convert the labels to vectors (4 x 1) each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(y_train, y_test):\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    y_train_vec  = mlb.fit_transform(map(str, y_train))\n",
    "    y_test_vec   = mlb.transform(map(str, y_test))\n",
    "    return y_train_vec, y_test_vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Run SVM and evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_SVM(X_train_vec, y_train_vec, X_test_vec, y_test_vec):\n",
    "    # Run SVM - fit and predict\n",
    "    SVM = OneVsRestClassifier(LinearSVC(), n_jobs=-1)\n",
    "    SVM.fit(X_train_vec, y_train_vec)\n",
    "    prediction = SVM.predict(X_test_vec)\n",
    "\n",
    "    # Evaluate the results\n",
    "    macro_f1 = f1_score(y_test_vec, prediction, average='macro')\n",
    "    weighted_f1 = f1_score(y_test_vec, prediction, average='weighted')\n",
    "    macro_precision = precision_score(y_test_vec, prediction, average='macro')\n",
    "    macro_recall = recall_score(y_test_vec, prediction, average='macro')\n",
    "\n",
    "    return macro_f1, weighted_f1, macro_precision, macro_recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Do an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def do_experiment(X_train, y_train, X_test, y_test):\n",
    "    # Convert texts to vectors\n",
    "    X_train_vec, X_test_vec = text_preprocessing(X_train, X_test)\n",
    "    y_train_vec, y_test_vec = one_hot_encoding(y_train, y_test)\n",
    "\n",
    "    # Run SVM and evaluate the results\n",
    "    macro_f1, weighted_f1, macro_precision, macro_recall = \\\n",
    "        evaluate_SVM(X_train_vec, y_train_vec, X_test_vec, y_test_vec)\n",
    "\n",
    "    # Show the indicators\n",
    "    print(\" macro_f1: %.4f , weighted_f1: %.4f, macro_precision: %.4f, macro_recall: %.4f\" %\n",
    "          (macro_f1, weighted_f1, macro_precision, macro_recall))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Main entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################\n",
      "Total data size:  41033\n",
      "Total train data size:  25033\n",
      "Total test data size:  8000\n"
     ]
    }
   ],
   "source": [
    "    dc = data_center(\"twitter_sentiment_data.csv\", test_size=8000, noisy_size=8000) # sizes represented in absolute values\n",
    "\n",
    "    print(\"####################################################\")\n",
    "    print(\"Total data size: \",       dc.get_len())\n",
    "    print(\"Total train data size: \", dc.get_train_len())\n",
    "    print(\"Total test data size: \",  dc.get_test_len())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "### Load the database and split it into training set, test set, noisy set, validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "### Get the test set for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "    X_test, y_test = dc.get_test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "### Run experiments with different training set, and use the same test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "Training set size: 2000 samples (8.0%): \n",
      " macro_f1: 0.4609 , weighted_f1: 0.5670, macro_precision: 0.6692, macro_recall: 0.4133\n",
      "Training set size: 2500 samples (10.0%): \n",
      " macro_f1: 0.4781 , weighted_f1: 0.5783, macro_precision: 0.6693, macro_recall: 0.4296\n",
      "Training set size: 4000 samples (16.0%): \n",
      " macro_f1: 0.5207 , weighted_f1: 0.6055, macro_precision: 0.6916, macro_recall: 0.4692\n",
      "Training set size: 5000 samples (20.0%): \n",
      " macro_f1: 0.5338 , weighted_f1: 0.6169, macro_precision: 0.6958, macro_recall: 0.4826\n",
      "Training set size: 7500 samples (30.0%): \n",
      " macro_f1: 0.5679 , weighted_f1: 0.6428, macro_precision: 0.7127, macro_recall: 0.5151\n",
      "Training set size: 10000 samples (39.9%): \n",
      " macro_f1: 0.5836 , weighted_f1: 0.6518, macro_precision: 0.7146, macro_recall: 0.5312\n",
      "-----------------------------------------------\n",
      "Noisy training set size: 2500 samples (2000 original, 500 noisy)\n",
      " macro_f1: 0.4155 , weighted_f1: 0.5121, macro_precision: 0.6028, macro_recall: 0.3431\n",
      "Noisy training set size: 5000 samples (4000 original, 1000 noisy)\n",
      " macro_f1: 0.4594 , weighted_f1: 0.5449, macro_precision: 0.6196, macro_recall: 0.3880\n",
      "Noisy training set size: 10000 samples (7500 original, 2500 noisy)\n",
      " macro_f1: 0.4740 , weighted_f1: 0.5491, macro_precision: 0.6246, macro_recall: 0.3962\n"
     ]
    }
   ],
   "source": [
    "    print(\"-----------------------------------------------\")\n",
    "    for size in [2000, 2500, 4000, 5000, 7500, 10000]:\n",
    "        # Get training set without noisy data\n",
    "        X_train, y_train = dc.get_train(size)\n",
    "        print(\"Training set size: %d samples (%.1f%%): \" % (len(X_train), len(y_train)/dc.get_train_len()*100))\n",
    "\n",
    "        # Do experiment\n",
    "        do_experiment(X_train, y_train, X_test, y_test)\n",
    "\n",
    "    print(\"-----------------------------------------------\")\n",
    "    for size in [(2000, 500), (4000, 1000), (7500, 2500)]:\n",
    "        # Get noisy training set\n",
    "        X_train, y_train = dc.get_train_with_noisy(size[0], size[1])\n",
    "        print(\"Noisy training set size: %d samples (%d original, %d noisy)\" % (len(y_train), size[0], size[1]))\n",
    "\n",
    "        # Do experiment\n",
    "        do_experiment(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
