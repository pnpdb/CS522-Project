{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "adcf3ad4",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "# SVM - Climate Sentiment Multiclass Classification\n",
        "## CS522 Project"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f69b1f5b",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "### Dataset: \n",
        "https://www.kaggle.com/code/luiskalckstein/climate-sentiment-multiclass-classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c742fe8-1acf-4783-8888-6a5ff744ca05",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "803ba8ae-b587-413e-b8fd-48aa4c7563c4",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.svm import LinearSVC\n",
        "from Common.DataCenter import data_center\n",
        "from Common.preprocessor import normalize_preprocessing\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea169203",
      "metadata": {
        "pycharm": {
          "metadata": false
        },
        "tags": []
      },
      "source": [
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "be3703ac-81e8-4ba0-848f-b9de87ac0543",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# parameter: original X of training set and test set\n",
        "# return:  vectorised X of training set and test set\n",
        "def text_preprocessing(X_train, X_test):\n",
        "    \n",
        "    # preprocessing with traditional NLP methodology\n",
        "    X_train_normalized = normalize_preprocessing(X_train)\n",
        "    X_test_normalized  = normalize_preprocessing(X_test)\n",
        "    \n",
        "    # vectorization\n",
        "    # Convert texts to vectors by TFIDF\n",
        "    vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
        "    X_train_vec  = vectorizer.fit_transform(X_train_normalized)\n",
        "    X_test_vec   = vectorizer.transform(X_test_normalized)\n",
        "      \n",
        "    return X_train_vec, X_test_vec"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b4d7615",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "### One-hot encoding, convert the labels to vectors (4 x 1) each"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e3a4ab11",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# parameter: original y of training set, original y of test set\n",
        "# return:  encoded y of training set and test set\n",
        "def one_hot_encoding(y_train, y_test):\n",
        "    mlb          = MultiLabelBinarizer()\n",
        "    y_train_vec  = mlb.fit_transform(map(str, y_train))\n",
        "    y_test_vec   = mlb.transform(map(str, y_test))\n",
        "    return y_train_vec, y_test_vec\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2eaf9b6",
      "metadata": {
        "pycharm": {
          "metadata": false
        },
        "tags": []
      },
      "source": [
        "### Run SVM and evaluate the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7660ca25",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# parameter:  vectorised X and encoded y of training set and test set\n",
        "def evaluate_SVM(X_train_vec, y_train_vec, X_test_vec, y_test_vec):\n",
        "    # Run SVM - fit and predict\n",
        "    SVM             = OneVsRestClassifier(LinearSVC(dual=False, class_weight='balanced'), n_jobs=-1)\n",
        "    SVM.fit(X_train_vec, y_train_vec)\n",
        "    prediction      = SVM.predict(X_test_vec)\n",
        "\n",
        "    # Evaluate the results\n",
        "    macro_f1        = f1_score(y_test_vec, prediction, average='macro')\n",
        "    weighted_f1     = f1_score(y_test_vec, prediction, average='weighted')\n",
        "    macro_precision = precision_score(y_test_vec, prediction, average='macro')\n",
        "    macro_recall    = recall_score(y_test_vec, prediction, average='macro')\n",
        "\n",
        "    return macro_f1, weighted_f1, macro_precision, macro_recall\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32c0772c",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "### Do an experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c55d424b",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Parameter: original X,y of training set and test set\n",
        "def do_experiment(X_train, y_train, X_test, y_test):\n",
        "    # Convert texts to vectors\n",
        "    X_train_vec, X_test_vec = text_preprocessing(X_train, X_test)\n",
        "    y_train_vec, y_test_vec = one_hot_encoding(y_train, y_test)\n",
        "    \n",
        "    # Run SVM and evaluate the results\n",
        "    macro_f1, weighted_f1, macro_precision, macro_recall = \\\n",
        "        evaluate_SVM(X_train_vec, y_train_vec, X_test_vec, y_test_vec)\n",
        "\n",
        "    # Show the indicators\n",
        "    print(\" macro_f1: %.4f , weighted_f1: %.4f, macro_precision: %.4f, macro_recall: %.4f\" %\n",
        "          (macro_f1, weighted_f1, macro_precision, macro_recall))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48af2d0a",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "### Print the distribution of labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc4ab027",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def print_distribution(hint, y):\n",
        "    df = data_center.df((y, y))\n",
        "    c = df['sentiment'].value_counts(sort = False)\n",
        "    l = len(df)\n",
        "    print(\"%s: %s\" % (hint, (\"%.1f%%, \"*(len(c)-1)+\"%.1f%%\") % tuple([x*100/l for x in list(c)])))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7000bb7a",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "### Main entry"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ca0d3ee",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "**Load the database and split it into training set, test set, noisy set, validation set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ba163848",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "####################################################\n",
            "Total data size:  41033\n",
            "Total train data size:  20033\n",
            "Total test data size:  8000\n"
          ]
        }
      ],
      "source": [
        "dc = data_center(\"twitter_sentiment_data_clean.csv\", test_size=4000, noisy_size=3000, validation_size=0)\n",
        "\n",
        "print(\"####################################################\")\n",
        "print(\"Total data size: \",       dc.get_len())\n",
        "print(\"Total train data size: \", dc.get_train_len())\n",
        "print(\"Total test data size: \",  dc.get_test_len())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "408a6679",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "**Get the test set for evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "31905bce",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "X_test, y_test = dc.get_test()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83f80cef",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "**Set distributions.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57f9921e",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# distribution of training set\n",
        "train_distribution = None\n",
        "\n",
        "# distribution of external noisy\n",
        "external_noisy_distribution = [0.25, 0.25, 0.25, 0.25]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7704d1b3",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "**Add the external noisy data.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "249444fe",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "dc.add_noisy(noisy_source=\"irrelevant\", distribution = external_noisy_distribution, size = 5000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dea92f2",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "**Run experiments with different training sets, and use the same test set.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f512a38d",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------\n",
            "Training set size: 1000 samples (5.0%): \n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "fit() got an unexpected keyword argument 'n_classes'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining set size: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m samples (\u001b[39m\u001b[38;5;132;01m%.1f\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(X_train), \u001b[38;5;28mlen\u001b[39m(y_train)\u001b[38;5;241m/\u001b[39mdc\u001b[38;5;241m.\u001b[39mget_train_len()\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m))\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Do an experiment\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mdo_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-----------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m size \u001b[38;5;129;01min\u001b[39;00m [(\u001b[38;5;241m2000\u001b[39m, \u001b[38;5;241m500\u001b[39m), (\u001b[38;5;241m4000\u001b[39m, \u001b[38;5;241m1000\u001b[39m), (\u001b[38;5;241m7500\u001b[39m, \u001b[38;5;241m2500\u001b[39m)]:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Get a noisy training set\u001b[39;00m\n",
            "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mdo_experiment\u001b[0;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m      5\u001b[0m y_train_vec, y_test_vec \u001b[38;5;241m=\u001b[39m one_hot_encoding(y_train, y_test)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Run SVM and evaluate the results\u001b[39;00m\n\u001b[1;32m      8\u001b[0m macro_f1, weighted_f1, macro_precision, macro_recall \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mevaluate_SVM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_vec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Show the indicators\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m macro_f1: \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m , weighted_f1: \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m, macro_precision: \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m, macro_recall: \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m     13\u001b[0m       (macro_f1, weighted_f1, macro_precision, macro_recall))\n",
            "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mevaluate_SVM\u001b[0;34m(X_train_vec, y_train_vec, X_test_vec, y_test_vec)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_SVM\u001b[39m(X_train_vec, y_train_vec, X_test_vec, y_test_vec):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Run SVM - fit and predict\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     SVM             \u001b[38;5;241m=\u001b[39m OneVsRestClassifier(LinearSVC(dual\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m), n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mSVM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     prediction      \u001b[38;5;241m=\u001b[39m SVM\u001b[38;5;241m.\u001b[39mpredict(X_test_vec)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Evaluate the results\u001b[39;00m\n",
            "\u001b[0;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'n_classes'"
          ]
        }
      ],
      "source": [
        "print(\"-----------------------------------------------\")\n",
        "for size in [3000, 6000, 7500, 12000, 15000, 22500, 30000]:\n",
        "    # Get a training set without noisy data\n",
        "    X_train, y_train = dc.get_train(size, train_distribution)\n",
        "    print(\"Training set size: %d samples: \" % (len(X_train)))\n",
        "    print_distribution(\" Sentiment distribution\", y_train)\n",
        "\n",
        "    # Do an experiment\n",
        "    do_experiment(X_train, y_train, X_test, y_test)\n",
        "\n",
        "print(\"-----------------------------------------------\")\n",
        "for size in [(6000, 1500), (12000, 3000), (22500, 7500)]:\n",
        "    # Get a noisy training set\n",
        "    X_train, y_train = dc.get_train_with_noisy(size[0], size[1], train_distribution)\n",
        "    print(\"Noisy training set size: %d samples (%d original, %d noisy)\" % (len(y_train), size[0], size[1]))\n",
        "    print_distribution(\"Sentiment distribution\", y_train)\n",
        "\n",
        "    # Do an experiment\n",
        "    do_experiment(X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88e38ecd",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "pytorch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "stem_cell": {
      "cell_type": "raw",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
