{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "# SVM - Climate Sentiment Multiclass Classification\n",
        "## CS522 Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "### Dataset: \n",
        "https://www.kaggle.com/code/luiskalckstein/climate-sentiment-multiclass-classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "import numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom cleanlab.classification import LearningWithNoisyLabels\nfrom Common.DataCenter import data_center\nfrom Common.preprocessor import normalize_preprocessing\nfrom Common.UtilFuncs import print_evaluation, Evaluator\n\n%matplotlib inline\n\nEv  \u003d Evaluator()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        },
        "tags": []
      },
      "source": "### Text preprocessing"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# parameter: original X of training set and test set\n",
        "# return:  vectorised X of training set and test set\n",
        "def text_preprocessing(X_train, X_test):\n",
        "    # preprocessing with traditional NLP methodology\n",
        "    X_train_normalized \u003d normalize_preprocessing(X_train)\n",
        "    X_test_normalized  \u003d normalize_preprocessing(X_test)\n",
        "    \n",
        "    # vectorization\n",
        "    # Convert texts to vectors by TFIDF\n",
        "    vectorizer \u003d TfidfVectorizer(ngram_range\u003d(1,2))\n",
        "    X_train_vec  \u003d vectorizer.fit_transform(X_train_normalized)\n",
        "    X_test_vec   \u003d vectorizer.transform(X_test_normalized)\n",
        "      \n",
        "    return X_train_vec, X_test_vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "### One-hot encoding, convert the labels to vectors (4 x 1) each"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# parameter: original y of training set, original y of test set\n",
        "# return:  encoded y of training set and test set\n",
        "def one_hot_encoding(y_train, y_test):\n",
        "    mlb          \u003d MultiLabelBinarizer()\n",
        "    y_train_vec  \u003d mlb.fit_transform(map(str, y_train))\n",
        "    y_test_vec   \u003d mlb.transform(map(str, y_test))\n",
        "    return y_train_vec, y_test_vec\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        },
        "tags": []
      },
      "source": [
        "### Run SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# parameter:  vectorised X and encoded y of training set and test set\n",
        "def run_SVM(X_train_vec, y_train_vec, X_test_vec, y_test_vec):\n",
        "    # Run SVM - fit and predict\n",
        "    SVM             \u003d OneVsRestClassifier(LinearSVC(dual\u003dFalse, class_weight\u003d\u0027balanced\u0027), n_jobs\u003d-1)\n",
        "    SVM.fit(X_train_vec, y_train_vec)\n",
        "    y_pred          \u003d SVM.predict(X_test_vec)\n",
        "    return  y_pred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "### Do an experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "# Parameter: original X,y of training set and test set\ndef do_experiment(X_train, y_train, X_test, y_test):\n    # Convert texts to vectors\n    X_train_vec, X_test_vec \u003d text_preprocessing(X_train, X_test)\n    y_train_vec, y_test_vec \u003d one_hot_encoding(y_train, y_test)\n\n    # Run SVM and evaluate the results\n    y_pred \u003d run_SVM(X_train_vec, y_train_vec, X_test_vec, y_test_vec)\n\n    # Print the evaluation\n    print_evaluation(y_test_vec, y_pred, labels\u003d[0,1,2,3])\n    evaluateDF \u003d Ev.evaluate(y_test_vec, y_pred)\n    return evaluateDF\n\n# do an experiment with denoise\n# Parameter: original X,y of training set and test set\ndef do_experiment_denoise(X_train, y_train, X_test, y_test):\n    # Convert texts to vectors\n    X_train_vec, X_test_vec \u003d text_preprocessing(X_train, X_test)\n    y_train_vec, y_test_vec \u003d one_hot_encoding(y_train, y_test)\n\n    # LearningWithNoisyLabels require the classifier has the entry predict_proba()\n    # So, use CalibratedClassifierCV to wrap LinearSVC\n    SVM \u003d CalibratedClassifierCV(LinearSVC(dual\u003dFalse, class_weight\u003d\u0027balanced\u0027))\n    rp \u003d LearningWithNoisyLabels(clf\u003dSVM, seed\u003d522)\n    rp.fit(X_train_vec, np.array(y_train))\n    y_pred \u003d rp.predict(X_test_vec)\n\n    # Print the evaluation\n    # One hot encoding for print_evaluation()\n    _, y_pred \u003d one_hot_encoding(y_train, y_pred)\n    print_evaluation(y_test_vec, y_pred, labels\u003d[0,1,2,3])\n\n    evaluateDF \u003d Ev.evaluate(y_test_vec, y_pred)\n    return evaluateDF\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "### Main entry\n**The settings of the noise sources.**"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "###################################### Data Summary #############################################\n",
            "  Raw set (not cleaned) size: 40908\n",
            "  Original set size: 40908\n",
            "      sentiments (\u0027Anti\u0027, \u0027Neutral\u0027, \u0027Pro\u0027, \u0027News\u0027): 9.4%, 18.3%, 50.2%, 22.1%\n",
            "  Training set size: 20000\n",
            "  Test set size: 4000\n",
            "  Noisy set size: 12000\n",
            "  Validation set size: 1000\n",
            "      noise sources (\u0027mislabeled\u0027, \u0027irrelevant\u0027, \u0027translated\u0027): 66.7%, 16.7%, 16.7%\n",
            "##################################################################################################\n",
            " noise noise_text  sentiment  origin(sentiment)  tweetid(partial)               message(partial)\n",
            "     1 mislabeled          3                  2            794664 RT @ChelseaClinton: Thank you \n",
            "     0       none          3                 -1            605804 Obama to follow Al Gore into c\n",
            "     2 irrelevant          1                 -1                -1 This is a CGI animated film ba\n",
            "     0       none          2                 -1            951653 umm ??? so itâ€™s basically su\n",
            "     1 mislabeled          0                  2            848920 RT @Colorlines: POC who live t\n",
            "     1 mislabeled          1                  3            798878 RT @ReutersLive: LIVE: U.S. Se\n",
            "     0       none          1                 -1            840241 @bradcarlson_ not denying clim\n",
            "     0       none          2                 -1            796429 RT @emmaroller: A climate chan\n",
            "     0       none          1                 -1            793214 @michellemalkin Trump wins ele\n",
            "     0       none          3                 -1            793175 Satellites help scientists see\n",
            "     0       none          2                 -1            819688 RT @Scientists4EU: Meh, why be\n",
            "     2 irrelevant          3                 -1                -1 @HalifaxReTales If you are goi\n",
            "     1 mislabeled          2                  3            829376 RT @DoNotForget911: Federal sc\n",
            "     2 irrelevant          0                 -1                -1 these chips are good, and bad,\n",
            "     2 irrelevant          3                 -1                -1 When I think #football, I thin\n"
          ]
        }
      ],
      "source": "#Each entry: source type and (size, distribution)\nnoisy_set_sizes \u003d {\n    \u0027mislabeled\u0027 : (8000, None),                   # max size: 15000\n    \u0027irrelevant\u0027 : (2000, [0.25,0.25,0.25,0.25]),  # max size: 34259\n    \u0027translated\u0027 : (2000, \"reserve_labels\"),       # max size: 5000\n}\n"
    },
    {
      "cell_type": "markdown",
      "source": "**Load the database and split it into training set, test set, noisy set, validation set**",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "# dc \u003d data_center(\"twitter_sentiment_data_clean.csv\", train_size \u003d 20000, test_size \u003d 4000, validation_size \u003d 1000,\n#                  noisy_size \u003d noisy_set_sizes[\u0027mislabeled\u0027][0] if \u0027mislabeled\u0027 in noisy_set_sizes.keys() else 0)\n\n# Load the database and split it into training set, test set, noisy set, validation set\n# Using noisy_set_sizes directly\ndc \u003d data_center(\"twitter_sentiment_data_clean.csv\", train_size \u003d 20000, test_size \u003d 4000, validation_size \u003d 1000,\n                 noisy_size \u003d noisy_set_sizes)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "**Show the summary of the whole data**",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": "dc.print_summary()\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "**To see the data features via a demo**",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "train_df \u003d dc.get_train_with_noisy_df(1000,1000)\ndata_center.print_data(train_df.head(15))\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "**Get the test set for evaluation.**"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "X_test, y_test \u003d dc.get_test()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "**Set distributions of training set.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# distribution of training set\n",
        "train_distribution \u003d None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "**Run experiments with different training sets, and use the same test set.**\n**Please wait some minutes until the finish message appears.**"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------- No noisy training sets ----------\n",
            "* Training set size: 2000 samples\n",
            "  Sentiments (\u0027Anti\u0027, \u0027Neutral\u0027, \u0027Pro\u0027, \u0027News\u0027): 9.4%, 18.3%, 50.2%, 22.1%\n",
            "    f1 of classes: [0.349, 0.315, 0.711, 0.678]\n",
            "    micro_f1: 0.626 , macro_f1: 0.513 , weighted_f1: 0.597, macro_precision: 0.592, macro_recall: 0.504\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "evaluate() missing 1 required positional argument: \u0027y_pred\u0027",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m\u003cipython-input-9-1c70b2af14b3\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Do an experiment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---\u003e 11\u001b[1;33m     \u001b[0mdfResult\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mdo_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     Evaluator.add_evaluation(dfResult, size, 0, \"-\",\n\u001b[0;32m     13\u001b[0m                               \u001b[0mdata_center\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalc_distribution_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\u0027sentiment\u0027\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m\u003cipython-input-5-d034b6a40bb6\u003e\u001b[0m in \u001b[0;36mdo_experiment\u001b[1;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Print the evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m\u003d\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---\u003e 12\u001b[1;33m     \u001b[0mevaluateDF\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mEvaluator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mevaluateDF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mTypeError\u001b[0m: evaluate() missing 1 required positional argument: \u0027y_pred\u0027"
          ]
        }
      ],
      "source": "expriment_no    \u003d 1\nprint(\"-------------- No noisy training sets ----------\")\nfor size in [2000, 4000, 5000, 8000, 10000, 15000, 20000]:\n    # Get a training set without noisy data\n    X_train, y_train \u003d dc.get_train(size, train_distribution)\n\n    print(\"* Training set size: %d samples\" % (len(y_train)))\n    data_center.print_distribution(\"  Sentiments\", y_train)\n\n    # Do an experiment\n    dfResult \u003d do_experiment(X_train, y_train, X_test, y_test)\n    Ev.add_evaluation(dfResult, size, 0, \"-\",\n                              data_center.calc_distribution_str(y_train, \u0027sentiment\u0027, [0,1,2,3]),\n                              \"-\", expriment_no\n                              )\n    expriment_no +\u003d 1\n\nprint(\"-------------- Noisy training sets -------------\")\n# The noise source distribution of the whole noisy data.\ndc.print_noise_source_distribution(\"General noise source distribution\")\n\nlstSizes \u003d [(4000, 1000), (8000, 2000), (15000, 5000)]\nfor size in lstSizes:\n    # Get a noisy training set\n    train_df         \u003d dc.get_train_with_noisy_df(size[0], size[1], train_distribution)\n    X_train, y_train \u003d data_center.Xy(train_df)\n    X_noisy          \u003d train_df[train_df[\u0027noise\u0027] !\u003d 0]\n\n    print(\"* Noisy training set size: %d samples (%d original, %d noisy)\" % (len(y_train), size[0], size[1]))\n    data_center.print_distribution(\"  Sentiments\", y_train)\n    dc.print_noise_source_distribution(\"  Noise sources\")\n\n    # Do an experiment without de-noising\n    print(\"  Before de-noising:\")\n    dfResult \u003d do_experiment(X_train, y_train, X_test, y_test)\n    Ev.add_evaluation(dfResult, size[0], size[1], \"N\",\n                            data_center.calc_distribution_str(y_train, \u0027sentiment\u0027, [0,1,2,3]),\n                            data_center.calc_distribution_str(X_noisy, \u0027noise\u0027, [1,2,3]),\n                            expriment_no\n                            )\n\n    # Do an experiment with de-noising\n    print(\"  After de-noising:\")\n    dfResult \u003d do_experiment_denoise(X_train, y_train, X_test, y_test)\n    Ev.add_evaluation(dfResult, size[0], size[1], \"Y\",\n                            data_center.calc_distribution_str(y_train, \u0027sentiment\u0027, [0,1,2,3]),\n                            data_center.calc_distribution_str(X_noisy, \u0027noise\u0027, [1,2,3]),\n                            expriment_no + len(lstSizes)\n                            )\n    expriment_no +\u003d 1\n    \nprint(\"-------------- Experiments are finished. -------------\")    \n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "**Show evaluations in a form (be sure the experiments have been finished)**"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "Ev.print()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": "**Parameters for plotting.**"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "# Plot training set size vs. Macro F1\n# x coordinate\nxValue  \u003d \"x[\u0027Origin\u0027]+x[\u0027Noise\u0027]\"\n# also can try other numeric columns, like:\n# xValue  \u003d \"x[\u0027Origin\u0027]\"\n\n# y coordinate\nyValue  \u003d \"y[\u0027Macro F1\u0027]\"\n# also can try other numeric columns, like:\n# yValue  \u003d \"y[\u0027Weighted F1\u0027]\"\n# yValue  \u003d \"y[\u0027Macro Precision\u0027]\"\n\n# Divide experiments into several groups, which will be plot as lines\nlines \u003d { # each item: name, filter\n    \u0027Original Data\u0027:      \"df[\u0027Denoised\u0027]\u003d\u003d\u0027-\u0027\",\n    \u0027Noisy Data\u0027:       \"df[\u0027Denoised\u0027]\u003d\u003d\u0027N\u0027\",\n    \u0027Denoised Data\u0027:    \"df[\u0027Denoised\u0027]\u003d\u003d\u0027Y\u0027\",\n}\n"
    },
    {
      "cell_type": "markdown",
      "source": "**Plot the evaluations.**",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "Ev.plot(xValue \u003d xValue, yValue \u003d yValue, lines \u003d lines,\n        title \u003d \u0027SVM using confident learning for de-noising\u0027)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "stem_cell": {
      "cell_type": "raw",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}