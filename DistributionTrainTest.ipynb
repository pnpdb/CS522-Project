{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# SVM - Climate Sentiment Multiclass Classification\n## CS522 Project",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Dataset: \nhttps://www.kaggle.com/code/luiskalckstein/climate-sentiment-multiclass-classification",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Imports",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "%matplotlib inline\n\n# Our base common modules\nfrom Common.UtilFuncs import Evaluator, Lab\n\n# Classifiers without denoising\nimport Common.SvmMethod as SvmMethod\nimport Common.BERTModel as BERTModel\n\n# Denoising Methodes\nimport Common.IsolationForestMethod as IsolationForestMethod\nimport Common.ConfidentLearningMethod as ConfidentLearningMethod\nimport Common.LocalOutlierFactorMethod as LocalOutlierFactorMethod\n\n# The settings of the noise sources.\n# Each item: source -\u003e (size, distribution)\nnoisy_set_sizes \u003d {\n    \u0027mislabeled\u0027 : (2000, None),                   # max size: 15000\n    \u0027irrelevant\u0027 : (2000, None),  # max size: 34259\n    \u0027translated\u0027 : (2000, \"reserve_labels\"),       # max size: 5000\n}\n\nlab \u003d Lab(\"twitter_sentiment_data_clean.csv\", noisy_sources \u003d noisy_set_sizes,\n          total_train_size \u003d 25000, total_test_size \u003d 12500, validation_size\u003d1400)\n\n# Choose a experiment without denoising\n# Each item: name -\u003e (funcion, whether choose) note:only the first active one will be used\nexperiment_without_denoising \u003d {\n    \u0027SVM\u0027 : (SvmMethod.do_experiment, 0),\n    \u0027BERT\u0027 : (BERTModel.do_experiment_BERT, lab.dc.get_validation_df(), 1)\n}\n\n# The training set of each experiment\n# origin_train_set_sizes \u003d [2000, 4000, 5000, 8000, 10000, 15000, 20000]\norigin_train_set_sizes \u003d [2000, 4000, 6000, 8000]\nnoisy_train_set_sizes  \u003d [(1500, 500), (3000, 1000), (4500,1500), (6000, 2000)]\n\ndistributions \u003d [(None, None),\n                 (None,[0.25,0.25,0.25,0.25]),\n                 ([0.25,0.25,0.25,0.25],None),\n                 ([0.25,0.25,0.25,0.25],[0.25,0.25,0.25,0.25]),\n                 ]\n\nlab_filename \u003d \"saving/\" + str(noisy_train_set_sizes) + \".pk\"\n\nRUN \u003d 1      #1/0:  Run new experiments / Read results made by previous experiments\nif RUN:\n    # Run new experiments\n    # Initialize the lab, which will run a serial of experiments\n\n    # Set the function to classify data without denoising\n    lab.set_experiment_no_denoising(experiment_without_denoising)\n\n    for n in range(2):\n        for i in range(len(distributions)):\n            # Set distributions of training and test\n            train_dist, test_dist \u003d distributions[i]\n            lab.set_distribution(train_dist, test_dist)\n\n            # Run experiment on original data\n            lab.do_batch_experiments(origin_train_set_sizes if n \u003d\u003d 0 else noisy_train_set_sizes)\n\n    # Save the results\n    lab.save(lab_filename)\nelse:\n    # Read evaluations saved by previous experiments\n    lab \u003d Lab.load(lab_filename)\n\n# Show evaluations in a form\nlab.print()\n\n# # Plot the evaluations\n# lab.plot()\n\n# Plot training set size vs. Macro F1\n\n# x coordinate\nxValue  \u003d \"x[\u0027Origin\u0027]+x[\u0027Noise\u0027]\"\n# y coordinate\nyValue  \u003d \"y[\u0027Macro F1\u0027]\"\nlen1 \u003d len(origin_train_set_sizes)\n# len2 \u003d len(noisy_train_set_sizes)   # assume len1 \u003d\u003d len2 for convenience\n\nxLabel  \u003d \"Training set size\\nno noise\"\n\n# Divide experiments into several groups, each will be plotted as a line\nlines \u003d { # each item: name, filter\n    \u0027Even-Even\u0027:         \"int((df[\u0027Experiment\u0027]-1)/%d)\u003d\u003d3\"%len1,\n    \u0027Origin-Origin\u0027:     \"int((df[\u0027Experiment\u0027]-1)/%d)\u003d\u003d0\"%len1,\n    \u0027Origin-Even\u0027:       \"int((df[\u0027Experiment\u0027]-1)/%d)\u003d\u003d1\"%len1,\n    \u0027Even-Origin\u0027:       \"int((df[\u0027Experiment\u0027]-1)/%d)\u003d\u003d2\"%len1,\n}\n\n# Do plot\nlab.Ev.plot(xValue \u003d xValue, yValue \u003d yValue, lines \u003d lines,\n            xLabel \u003d xLabel, title \u003d \"SVM effected by different distribution\")\n\n\nxLabel  \u003d \"Training set size\\nnoisy sets: %s\" % \\\n          str([str(x[0])+\u0027+\u0027+str(x[1]) for x in noisy_train_set_sizes]).replace(\"\\\u0027\",\"\")\n\n# Divide experiments into several groups, each will be plotted as a line\nlines \u003d { # each item: name, filter\n    \u0027Even-Even\u0027:         \"int((df[\u0027Experiment\u0027]-1)/%d)\u003d\u003d7\"%len1,\n    \u0027Origin-Origin\u0027:     \"int((df[\u0027Experiment\u0027]-1)/%d)\u003d\u003d4\"%len1,\n    \u0027Origin-Even\u0027:       \"int((df[\u0027Experiment\u0027]-1)/%d)\u003d\u003d5\"%len1,\n    \u0027Even-Origin\u0027:       \"int((df[\u0027Experiment\u0027]-1)/%d)\u003d\u003d6\"%len1,\n}\n\n# Do plot\nlab.Ev.plot(xValue \u003d xValue, yValue \u003d yValue, lines \u003d lines,\n            xLabel \u003d xLabel, title \u003d \"SVM effected by different distribution\")\n\n\nlab.Ev.get_evaluate(\"/saving/distri_step.csv\")",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}