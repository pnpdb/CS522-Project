{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22460778",
   "metadata": {},
   "source": [
    "# BERT - Climate Sentiment Multiclass Classification\n",
    "## CS522 Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6829ff32",
   "metadata": {},
   "source": [
    "**Dataset:**  \n",
    "https://www.kaggle.com/code/luiskalckstein/climate-sentiment-multiclass-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad0fd68",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65f1e0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 0 ns (started: 2022-04-21 09:46:36 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# ! pip install tensorflow-addons\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import DistilBertTokenizer, TFDistilBertModel, DistilBertConfig\n",
    "from transformers import logging as hf_logging\n",
    "from Common.preprocessor import one_hot_encoding\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from Common.UtilFuncs import DataSize\n",
    "from Common.DataCenter import data_center\n",
    "from Common.UtilFuncs import print_evaluation, print_distribution\n",
    "from Common.UtilFuncs import Evaluator, Lab\n",
    "from Common.BERTModel import BERTModel\n",
    "try:\n",
    "    %load_ext autotime\n",
    "except:\n",
    "    !pip install ipython-autotime\n",
    "    %load_ext autotime\n",
    "    \n",
    "hf_logging.set_verbosity_error()\n",
    "warnings.filterwarnings('ignore')\n",
    "# ! pip install tensorflow-addons\n",
    "TrainSizeBaseLine = DataSize.GetTrainSizeBaseline()\n",
    "TrainSizeWithNoisyData = DataSize.GetTrainSizeWithNoisyData()\n",
    "# 4000\n",
    "TestDataSize = DataSize.GetTestDataSize()\n",
    "NoiseDataSize = DataSize.GetNoiseDataSize()\n",
    "ValidationDataSize = DataSize.GetValidationDataSize()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fc21ad",
   "metadata": {},
   "source": [
    "**Detect GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb1f2768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set memory autoincrement\n",
      "Physical GPUs: 1, Logical GPUs: 1\n",
      "time: 0 ns (started: 2022-04-21 09:23:42 +08:00)\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print('Set memory autoincrement')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print('Physical GPUs: %d, Logical GPUs: %d' % (len(gpus), len(logical_gpus)))\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print('GPUs not detected')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad44c4b6",
   "metadata": {},
   "source": [
    "## 1. Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26a703a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 562 ms (started: 2022-04-21 09:46:39 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# Each item: source -> (size, distribution)\n",
    "noisy_set_sizes = {\n",
    "    'mislabeled' : (8600, None),                   # max size: 15000\n",
    "    'irrelevant' : (8600, [0.25,0.25,0.25,0.25]),  # max size: 34259\n",
    "    'translated' : (5000, \"reserve_labels\"),       # max size: 5000\n",
    "}\n",
    "lab = Lab(\"twitter_sentiment_data_clean.csv\", noisy_sources = noisy_set_sizes, total_train_size = 20000, total_test_size = 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b52c2ddc",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################################### Data Summary #############################################\n",
      "  Original set size: 40908\n",
      "      sentiments ('Anti', 'Neutral', 'Pro', 'News'): 9.4%, 18.3%, 50.2%, 22.1%\n",
      "  Training set size: 20000\n",
      "  Test set size: 4000\n",
      "  Noisy set size: 22200\n",
      "  Validation set size: 1000\n",
      "      noise sources ('mislabeled', 'irrelevant', 'translated'): 38.7%, 38.7%, 22.5%\n",
      "##################################################################################################\n",
      "time: 0 ns (started: 2022-04-21 09:46:40 +08:00)\n"
     ]
    }
   ],
   "source": [
    "lab.dc.print_summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119126e4",
   "metadata": {},
   "source": [
    "Observe the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "403444a7",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noise</th>\n",
       "      <th>noise_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>origin(sentiment)</th>\n",
       "      <th>tweetid...</th>\n",
       "      <th>message...</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>mislabeled</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8108306943</td>\n",
       "      <td>Regional/Global seabird stress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>9536174384</td>\n",
       "      <td>I have to write an essay over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>mislabeled</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8645926535</td>\n",
       "      <td>Barack Obama warns climate cha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>8199736905</td>\n",
       "      <td>RT @mitskileaks: want to speci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>8438476460</td>\n",
       "      <td>.@RepBrianFitz Thank you for a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>8182648187</td>\n",
       "      <td>RT @billmckibben: Reading clim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>9556340417</td>\n",
       "      <td>RT @LanreShaper: 'Africa contr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>mislabeled</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9587601354</td>\n",
       "      <td>Keilmuan itu politik. Hawong N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>8401717188</td>\n",
       "      <td>RT @WRIClimate: @CNBC He shoul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>8254569694</td>\n",
       "      <td>@magslol global warming is a C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>@chetan_bhagat And morons like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>8278157032</td>\n",
       "      <td>A climate change economist sou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>7328403750</td>\n",
       "      <td>RT @tveitdal: Climate change:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>8496410900</td>\n",
       "      <td>Now is the time to prepare for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>7597927163</td>\n",
       "      <td>GOP: Stop Denying Climate Chan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    noise  noise_text  sentiment origin(sentiment)  tweetid...  \\\n",
       "0       1  mislabeled          3                 2  8108306943   \n",
       "1       0        none          2                 -  9536174384   \n",
       "2       1  mislabeled          1                 3  8645926535   \n",
       "3       0        none          2                 -  8199736905   \n",
       "4       0        none          2                 -  8438476460   \n",
       "5       0        none          2                 -  8182648187   \n",
       "6       0        none          2                 -  9556340417   \n",
       "7       1  mislabeled          3                 1  9587601354   \n",
       "8       0        none          2                 -  8401717188   \n",
       "9       0        none          0                 -  8254569694   \n",
       "10      2  irrelevant          3                 -           -   \n",
       "11      0        none          3                 -  8278157032   \n",
       "12      0        none          3                 -  7328403750   \n",
       "13      0        none          2                 -  8496410900   \n",
       "14      0        none          2                 -  7597927163   \n",
       "\n",
       "                        message...  \n",
       "0   Regional/Global seabird stress  \n",
       "1   I have to write an essay over   \n",
       "2   Barack Obama warns climate cha  \n",
       "3   RT @mitskileaks: want to speci  \n",
       "4   .@RepBrianFitz Thank you for a  \n",
       "5   RT @billmckibben: Reading clim  \n",
       "6   RT @LanreShaper: 'Africa contr  \n",
       "7   Keilmuan itu politik. Hawong N  \n",
       "8   RT @WRIClimate: @CNBC He shoul  \n",
       "9   @magslol global warming is a C  \n",
       "10  @chetan_bhagat And morons like  \n",
       "11  A climate change economist sou  \n",
       "12  RT @tveitdal: Climate change:   \n",
       "13  Now is the time to prepare for  \n",
       "14  GOP: Stop Denying Climate Chan  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 47 ms (started: 2022-04-21 09:47:47 +08:00)\n"
     ]
    }
   ],
   "source": [
    "train_df = lab.dc.get_train_with_noisy_df(15000,5000)\n",
    "data_center.print_data(train_df.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2eddc4",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# do an experiment without denoising\n",
    "# Parameter: original X,y of training set and test set\n",
    "# Return evaluation info\n",
    "def do_experiment(train_df, test_df):\n",
    "    X_train, y_train = data_center.Xy(train_df)\n",
    "    X_test, y_test   = data_center.Xy(test_df)\n",
    "    \n",
    "    valSet = lab.dc.get_validation()\n",
    "    X_val = valSet[0]\n",
    "    y_val = valSet[1]\n",
    "\n",
    "    X_train_token = tokenize(X_train)\n",
    "    X_test_token = tokenize(X_test)\n",
    "    X_val_token = tokenize(X_val)\n",
    "\n",
    "    y_train_vec, y_test_vec = one_hot_encoding(y_train, y_test)\n",
    "    y_val_vec = one_hot_encoding(y_val)\n",
    "\n",
    "    \n",
    "    # Convert texts to vectors\n",
    "    bert = BERTModel()\n",
    "    bert.Init()\n",
    "\n",
    "    bert.Train(X_train_token, y_train_vec, X_val_token, y_val_vec)\n",
    "    y_pred = bert.Predict(X_test_token)\n",
    "    \n",
    "\n",
    "    # Print the evaluation\n",
    "    print_evaluation(y_test_vec, y_pred, labels=[0,1,2,3])\n",
    "    evaluateDF = Evaluator.do_evaluate(y_test_vec, y_pred)\n",
    "    return evaluateDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6fef197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 217 µs (started: 2022-04-20 22:57:55 +08:00)\n"
     ]
    }
   ],
   "source": [
    "def dc_format(D):\n",
    "    data = {'message':D[0] , 'sentiment':D[1]}\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cc2be9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 4000\n",
      "Validation size: 1000\n",
      "time: 107 ms (started: 2022-04-20 22:57:55 +08:00)\n"
     ]
    }
   ],
   "source": [
    "noisy_set_sizes = {\n",
    "    'mislabeled' : 5000,   # max size: 15000\n",
    "    'irrelevant' : 5000,   # max size: 34259\n",
    "    'translated' : 5000,   # max size: 5000\n",
    "}\n",
    "\n",
    "# Load the database and split it into training set, test set, noisy set, validation set\n",
    "dc = data_center('twitter_sentiment_data_clean.csv', test_size = 4000, validation_size = 1000,\n",
    "                 noisy_size = noisy_set_sizes['mislabeled'])\n",
    "\n",
    "test_df = dc_format(dc.get_test())\n",
    "val_df = dc_format(dc.get_validation())\n",
    "\n",
    "print(f\"Test size: {test_df.shape[0]}\")\n",
    "print(f\"Validation size: {val_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7e9e22",
   "metadata": {},
   "source": [
    "### Prepare the noisy set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a3d316e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noisy set size is 5000\n",
      "5000 noisy samples added\n",
      "5000 noisy samples added\n",
      "Noisy set new size is 15000\n",
      "time: 306 ms (started: 2022-04-20 22:57:55 +08:00)\n"
     ]
    }
   ],
   "source": [
    "lstNoisyInfo = [(\"mislabeled\",dc.get_noisy_len())]\n",
    "print(\"Noisy set size is %d\"                % dc.get_noisy_len())\n",
    "\n",
    "# add the external noisy data (irrelevant texts)\n",
    "# distribution of irrelevant noisy\n",
    "irrelevant_noisy_distribution = [0.25, 0.25, 0.25, 0.25]    # None, if use the distribution of original set\n",
    "added_size = dc.add_noisy(noisy_source=\"irrelevant\", distribution = irrelevant_noisy_distribution,\n",
    "                          size = noisy_set_sizes['irrelevant'])\n",
    "print(\"%d noisy samples added\" % added_size)\n",
    "lstNoisyInfo.append((\"irrelevant\",added_size))\n",
    "\n",
    "# add the external noisy data (translated texts). use the labels of each noisy data\n",
    "added_size = dc.add_noisy(noisy_source=\"translated\", distribution = \"reserve_labels\", \n",
    "                          size = noisy_set_sizes['translated'])\n",
    "print(\"%d noisy samples added\" % added_size)\n",
    "lstNoisyInfo.append((\"translated\",added_size))\n",
    "\n",
    "print(\"Noisy set new size is %d\"                % dc.get_noisy_len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9b42eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2000, 4000, 5000, 8000, 10000, 15000, 20000]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.54 ms (started: 2022-04-20 22:57:56 +08:00)\n"
     ]
    }
   ],
   "source": [
    "TrainSizeBaseLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "969dce28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4000, 1000), (8000, 2000), (15000, 5000)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 735 µs (started: 2022-04-20 22:57:56 +08:00)\n"
     ]
    }
   ],
   "source": [
    "TrainSizeWithNoisyData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "321c4675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 115 µs (started: 2022-04-20 22:57:56 +08:00)\n"
     ]
    }
   ],
   "source": [
    "train_distribution = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1799cae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 51.1 ms (started: 2022-04-20 22:57:56 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# 2000\n",
    "train_df_2000 = dc_format(dc.get_train(TrainSizeBaseLine[0], train_distribution))\n",
    "# 4000\n",
    "train_df_4000 = dc_format(dc.get_train(TrainSizeBaseLine[1], train_distribution))\n",
    "# 5000\n",
    "train_df_5000 = dc_format(dc.get_train(TrainSizeBaseLine[2], train_distribution))\n",
    "# 8000\n",
    "train_df_8000 = dc_format(dc.get_train(TrainSizeBaseLine[3], train_distribution))\n",
    "# 10000\n",
    "train_df_10000 = dc_format(dc.get_train(TrainSizeBaseLine[4], train_distribution))\n",
    "# 15000\n",
    "train_df_15000 = dc_format(dc.get_train(TrainSizeBaseLine[5], train_distribution))\n",
    "# 20000\n",
    "train_df_20000 = dc_format(dc.get_train(TrainSizeBaseLine[6], train_distribution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e743a730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 55.2 ms (started: 2022-04-20 22:57:56 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# (4000, 1000)\n",
    "train_df_4000_1000 = dc_format(dc.get_train_with_noisy(TrainSizeWithNoisyData[0][0], TrainSizeWithNoisyData[0][1], train_distribution))\n",
    "# (8000, 2000)\n",
    "train_df_8000_2000 = dc_format(dc.get_train_with_noisy(TrainSizeWithNoisyData[1][0], TrainSizeWithNoisyData[1][1], train_distribution))\n",
    "# (15000, 5000)\n",
    "train_df_15000_5000 = dc_format(dc.get_train_with_noisy(TrainSizeWithNoisyData[2][0], TrainSizeWithNoisyData[2][1], train_distribution))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a432e6f5",
   "metadata": {},
   "source": [
    "### <font color='red'> Specified training set </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84e8a52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 159 µs (started: 2022-04-20 22:57:56 +08:00)\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df_15000_5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae31d23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @theblaze: ‘Bombshell’ climate-change study...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have to write an essay over the psychologica...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@NASA @MatthewACherry Can we make it to one of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @mitskileaks: want to specify that $ is don...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.@RepBrianFitz Thank you for acknowleding man'...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  sentiment\n",
       "0  RT @theblaze: ‘Bombshell’ climate-change study...          3\n",
       "1  I have to write an essay over the psychologica...          2\n",
       "2  @NASA @MatthewACherry Can we make it to one of...          1\n",
       "3  RT @mitskileaks: want to specify that $ is don...          2\n",
       "4  .@RepBrianFitz Thank you for acknowleding man'...          2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.48 ms (started: 2022-04-20 22:57:56 +08:00)\n"
     ]
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc9795e",
   "metadata": {},
   "source": [
    "#### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa5b8e97",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\workspace\\CS522-Project\\tf_bert-NoiseCompare.ipynb Cell 21'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/workspace/CS522-Project/tf_bert-NoiseCompare.ipynb#ch0000020?line=0'>1</a>\u001b[0m le \u001b[39m=\u001b[39m LabelEncoder()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/workspace/CS522-Project/tf_bert-NoiseCompare.ipynb#ch0000020?line=1'>2</a>\u001b[0m train_df[\u001b[39m'\u001b[39m\u001b[39msparse_label\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m le\u001b[39m.\u001b[39mfit_transform(train_df[\u001b[39m'\u001b[39m\u001b[39msentiment\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/workspace/CS522-Project/tf_bert-NoiseCompare.ipynb#ch0000020?line=2'>3</a>\u001b[0m val_df[\u001b[39m'\u001b[39m\u001b[39msparse_label\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m le\u001b[39m.\u001b[39mtransform(val_df[\u001b[39m'\u001b[39m\u001b[39msentiment\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/workspace/CS522-Project/tf_bert-NoiseCompare.ipynb#ch0000020?line=3'>4</a>\u001b[0m test_df[\u001b[39m'\u001b[39m\u001b[39msparse_label\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m le\u001b[39m.\u001b[39mtransform(test_df[\u001b[39m'\u001b[39m\u001b[39msentiment\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 422 ms (started: 2022-04-21 09:30:44 +08:00)\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "train_df['sparse_label'] = le.fit_transform(train_df['sentiment'])\n",
    "val_df['sparse_label'] = le.transform(val_df['sentiment'])\n",
    "test_df['sparse_label'] = le.transform(test_df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93072cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "time: 2.78 ms (started: 2022-04-20 22:57:56 +08:00)\n"
     ]
    }
   ],
   "source": [
    "label_dict = (train_df[['sentiment','sparse_label']].drop_duplicates()\n",
    "              .sort_values(by='sparse_label')\n",
    "              .reset_index(drop=True)['sentiment']\n",
    "              .to_dict())\n",
    "\n",
    "for index, key in label_dict.items():\n",
    "    print(index, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35b6194",
   "metadata": {},
   "source": [
    "#### Splitting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5fc9e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 training samples\n",
      "1000 validation samples\n",
      "time: 428 µs (started: 2022-04-20 22:57:56 +08:00)\n"
     ]
    }
   ],
   "source": [
    "x_train = train_df['message']\n",
    "y_train = train_df['sparse_label']\n",
    "\n",
    "x_val = val_df['message']\n",
    "y_val = val_df['sparse_label']\n",
    "\n",
    "print(f\"{len(x_train)} training samples\\n{len(x_val)} validation samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86b5fa3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 testing samples\n",
      "time: 362 µs (started: 2022-04-20 22:57:56 +08:00)\n"
     ]
    }
   ],
   "source": [
    "x_test = test_df['message']\n",
    "y_test = test_df['sparse_label']\n",
    "print(f\"{len(x_test)} testing samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdca5603",
   "metadata": {},
   "source": [
    "## 2. Train BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2087abe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 605 µs (started: 2022-04-20 22:57:56 +08:00)\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'distilbert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "764bf707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.68 s (started: 2022-04-20 22:57:56 +08:00)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5f1cf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum amount of tokens in the dataset is 6282\n",
      "time: 5.88 s (started: 2022-04-20 22:58:03 +08:00)\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for sentence in (x_train.tolist() + x_val.tolist()):\n",
    "    try:\n",
    "        sentence_token_len = len(tokenizer.tokenize(sentence))\n",
    "        max_len = sentence_token_len if (sentence_token_len > max_len) else max_len\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "print(f\"The maximum amount of tokens in the dataset is {max_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f79223b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.15 s (started: 2022-04-20 22:58:09 +08:00)\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 360\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(MODEL_NAME,  \n",
    "                                                add_special_tokens=True,\n",
    "                                                max_length=MAX_LEN, \n",
    "                                                pad_to_max_length=True)\n",
    "\n",
    "def tokenize(sentences):\n",
    "    input_ids, input_masks, input_segments = [], [], []\n",
    "    for sentence in tqdm(sentences):\n",
    "        inputs = tokenizer.encode_plus(sentence, \n",
    "                                       add_special_tokens=True, \n",
    "                                       max_length=MAX_LEN, \n",
    "                                       pad_to_max_length=True, \n",
    "                                       return_attention_mask=True, \n",
    "                                       return_token_type_ids=True, \n",
    "                                       truncation=True)\n",
    "        input_ids.append(inputs['input_ids'])\n",
    "        input_masks.append(inputs['attention_mask'])\n",
    "        input_segments.append(inputs['token_type_ids'])       \n",
    "        \n",
    "    return np.asarray(input_ids, dtype='int32'), np.asarray(input_masks, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f71606e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 20000/20000 [00:07<00:00, 2814.03it/s]\n",
      "100%|█████████████████████████████████████| 1000/1000 [00:00<00:00, 3447.51it/s]\n",
      "100%|█████████████████████████████████████| 4000/4000 [00:01<00:00, 3504.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.07 s (started: 2022-04-20 22:58:17 +08:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = tokenize(x_train)\n",
    "X_val = tokenize(x_val)\n",
    "X_test = tokenize(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0999e68e",
   "metadata": {},
   "source": [
    "#### Add custom layers after embedding model for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0dbacad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 22:58:29.397312: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x107aa2fa0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x107aa2fa0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "time: 5.06 s (started: 2022-04-20 22:58:26 +08:00)\n"
     ]
    }
   ],
   "source": [
    "bert_config = DistilBertConfig.from_pretrained(MODEL_NAME, output_hidden_states=True, output_attentions=True)\n",
    "TFBert = TFDistilBertModel.from_pretrained(MODEL_NAME, config=bert_config)\n",
    "\n",
    "input_ids_layer = tf.keras.layers.Input(shape=(MAX_LEN,), name='input_token', dtype='int32')\n",
    "input_masks_layer = tf.keras.layers.Input(shape=(MAX_LEN,), name='masked_token', dtype='int32') \n",
    "\n",
    "X = TFBert(input_ids = input_ids_layer, attention_mask = input_masks_layer)[0]\n",
    "# X = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True))(X)\n",
    "# X = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128))(X)\n",
    "X = tf.keras.layers.Dropout(0.2)(X)\n",
    "X = tf.keras.layers.Dense(1024, activation=tfa.activations.mish)(X)\n",
    "X = tf.keras.layers.Flatten()(X)\n",
    "X = tf.keras.layers.Dense(4, activation=tf.nn.softmax)(X)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_ids_layer, input_masks_layer], outputs = X)\n",
    "\n",
    "for layer in model.layers[:3]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53499395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_token (InputLayer)       [(None, 360)]        0           []                               \n",
      "                                                                                                  \n",
      " masked_token (InputLayer)      [(None, 360)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_distil_bert_model (TFDistil  TFBaseModelOutput(l  66362880   ['input_token[0][0]',            \n",
      " BertModel)                     ast_hidden_state=(N               'masked_token[0][0]']           \n",
      "                                one, 360, 768),                                                   \n",
      "                                 hidden_states=((No                                               \n",
      "                                ne, 360, 768),                                                    \n",
      "                                 (None, 360, 768),                                                \n",
      "                                 (None, 360, 768),                                                \n",
      "                                 (None, 360, 768),                                                \n",
      "                                 (None, 360, 768),                                                \n",
      "                                 (None, 360, 768),                                                \n",
      "                                 (None, 360, 768)),                                               \n",
      "                                 attentions=((None,                                               \n",
      "                                 12, None, 360),                                                  \n",
      "                                 (None, 12, None, 3                                               \n",
      "                                60),                                                              \n",
      "                                 (None, 12, None, 3                                               \n",
      "                                60),                                                              \n",
      "                                 (None, 12, None, 3                                               \n",
      "                                60),                                                              \n",
      "                                 (None, 12, None, 3                                               \n",
      "                                60),                                                              \n",
      "                                 (None, 12, None, 3                                               \n",
      "                                60)))                                                             \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 360, 768)     0           ['tf_distil_bert_model[0][13]']  \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 360, 1024)    787456      ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 368640)       0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 4)            1474564     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 68,624,900\n",
      "Trainable params: 68,624,900\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "time: 8.66 ms (started: 2022-04-20 22:58:32 +08:00)\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5039ea",
   "metadata": {},
   "source": [
    "#### Model callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "437fd5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 230 µs (started: 2022-04-20 22:58:32 +08:00)\n"
     ]
    }
   ],
   "source": [
    "ckpt_dir = './ckpt'\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f94e83c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 520 µs (started: 2022-04-20 22:58:32 +08:00)\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = ModelCheckpoint(filepath=ckpt_dir + '/weights_val_best.hdf5',\n",
    "                                   monitor='val_accuracy',\n",
    "                                   save_weights_only=True,\n",
    "                                   save_best_only=True,\n",
    "                                   verbose=0)\n",
    "\n",
    "early_stopping = EarlyStopping(patience=3,\n",
    "                               monitor='val_accuracy',\n",
    "                               min_delta=0,\n",
    "                               mode='max',\n",
    "                               restore_best_weights=False,\n",
    "                               verbose=1)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              min_lr=0.000001,\n",
    "                              patience=1,\n",
    "                              mode='min',\n",
    "                              factor=0.1,\n",
    "                              min_delta=0.0001,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf49083d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 22:58:32.130367: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 22:58:34.198153: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 130/2500 [>.............................] - ETA: 50:28 - loss: 1.2277 - accuracy: 0.4846"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      2\u001b[0m               optimizer\u001b[38;5;241m=\u001b[39mtfa\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mRectifiedAdam(\u001b[38;5;241m0.0001\u001b[39m),\n\u001b[1;32m      3\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tfgpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/tfgpu/lib/python3.8/site-packages/keras/engine/training.py:1389\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1388\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1389\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1391\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tfgpu/lib/python3.8/site-packages/keras/callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 438\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tfgpu/lib/python3.8/site-packages/keras/callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 297\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    300\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/tfgpu/lib/python3.8/site-packages/keras/callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m   batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    316\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 318\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    321\u001b[0m   end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/miniforge3/envs/tfgpu/lib/python3.8/site-packages/keras/callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    355\u001b[0m   hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 356\u001b[0m   \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    359\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/miniforge3/envs/tfgpu/lib/python3.8/site-packages/keras/callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1034\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tfgpu/lib/python3.8/site-packages/keras/callbacks.py:1106\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1105\u001b[0m   \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1106\u001b[0m   logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1107\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/tfgpu/lib/python3.8/site-packages/keras/utils/tf_utils.py:563\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[1;32m    561\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m--> 563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tfgpu/lib/python3.8/site-packages/tensorflow/python/util/nest.py:914\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    910\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    911\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    915\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/miniforge3/envs/tfgpu/lib/python3.8/site-packages/tensorflow/python/util/nest.py:914\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    910\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    911\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    915\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/miniforge3/envs/tfgpu/lib/python3.8/site-packages/keras/utils/tf_utils.py:557\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    555\u001b[0m   \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    556\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 557\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m   \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/miniforge3/envs/tfgpu/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1223\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1201\u001b[0m \n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1223\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/miniforge3/envs/tfgpu/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1189\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1188\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1190\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2min 55s (started: 2022-04-20 22:58:32 +08:00)\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=tfa.optimizers.RectifiedAdam(0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=8,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[model_checkpoint, early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25f6a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, metric, title=''):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(history.history[metric],  label='Training')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc93dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'accuracy', 'Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a356af1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'loss', 'Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00915496",
   "metadata": {},
   "source": [
    "#### Loading the best model and test on a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d499d7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(ckpt_dir + '/weights_val_best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c85039",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = model.predict(X_test)\n",
    "y_pred = np.argmax(pred_probs, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c720f092",
   "metadata": {},
   "source": [
    "#### Visualizing Confusion Matrix using Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ef0cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c666da",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_names = ['Anti','Neutral','Pro','News'] \n",
    "class_names=[0, 1, 2, 3]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "\n",
    "sns.set(font_scale = 1.2, color_codes=True, palette='deep')\n",
    "sns.heatmap(pd.DataFrame(cm, index=labels_names ,columns=class_names), annot=True, annot_kws = {'size':16}, cmap='YlGnBu' ,fmt='g')\n",
    "ax.xaxis.set_label_position('top')\n",
    "plt.xticks(class_names, labels_names, rotation=45)\n",
    "plt.yticks(class_names, labels_names, rotation=45)\n",
    "plt.title('Confusion matrix', y=1.2)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "print('Test Accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274021af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=labels_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d29869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mf = f1_score(y_test, y_pred, average='macro')\n",
    "# wf = f1_score(y_test, y_pred, average='weighted')\n",
    "# mp = precision_score(y_test, y_pred, average='macro')\n",
    "# mr = recall_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c99bdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\n",
    "#     f'Macro F1: {mf: .3f} \\\n",
    "#     | Weighted F1: {wf: .3f} \\\n",
    "#     | Macro Precision: {mp: .3f} \\\n",
    "#     | Macro recall: {mr: .3f}'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38d5526",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_evaluation(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc7e7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
